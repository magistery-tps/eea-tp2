# install.packages(pacman)
library(pacman)
p_load(tidyverse, tidymodels, rsample, ggplot2, GGally, caret)
# Lectura
data <- as.data.frame(read.csv(file = "coffee_ratings.csv", encoding='UTF-8'))
# Resumen
data %>% glimpse()
# Primeros Registros
head(data)
# install.packages(pacman)
library(pacman)
p_load(tidyverse, tidymodels, rsample, ggplot2, GGally, caret)
# Lectura
data <- as.data.frame(read.csv(file = "../datasets/coffee_ratings.csv", encoding='UTF-8'))
# Resumen
data %>% glimpse()
# Primeros Registros
head(data)
conteo_na =  data %>% gather(., key = "variables", value = "valores") %>%
group_by(variables) %>%
summarise(valores_unicos = n_distinct(valores),
cantidad_na = sum(is.na(valores)),
porcentaje_na = sum(is.na(valores))/nrow(train)*100) %>%
arrange(desc(porcentaje_na), valores_unicos)
conteo_na
# install.packages(pacman)
library(pacman)
p_load(tidyverse, tidymodels, rsample, ggplot2, GGally, caret)
p_load_gh('adrianmarino/commons')
import('../src/dataset.R')
# Lectura
data <- as.data.frame(read.csv(file = "../datasets/coffee_ratings.csv", encoding='UTF-8'))
# Resumen
data %>% glimpse()
show_values(data)
data %>%
janitor::clean_names()
# install.packages(pacman)
library(pacman)
p_load(tidyverse, tidymodels, rsample, ggplot2, GGally, caret, janitor)
p_load_gh('adrianmarino/commons')
import('../src/dataset.R')
data %>%
janitor::clean_names()
# install.packages(pacman)
library(pacman)
p_load(tidyverse, tidymodels, rsample, ggplot2, GGally, caret, janitor)
p_load_gh('adrianmarino/commons')
import('../src/dataset.R')
dataset <- load_dataset()
# Resumen
dataset %>% glimpse()
# Primeros Registros
head(dataset)
show_values(dataset)
conteo_na =  dataset %>% gather(., key = "variables", value = "valores") %>%
group_by(variables) %>%
summarise(valores_unicos = n_distinct(valores),
cantidad_na = sum(is.na(valores)),
porcentaje_na = sum(is.na(valores))/nrow(train)*100) %>%
arrange(desc(porcentaje_na), valores_unicos)
conteo_na
library(readr)
fastfood_calories <- read_csv("datasets/fastfood_calories.csv")
View(fastfood_calories)
library(tidyverse)
library(corrr)
library(pacman)
p_load(tidyverse, corrr, knitr, kableExtra)
# leo el archivo ar_properties
datos <- read_csv("../Fuentes/ar_properties.csv")
glimpse(datos)
# filtrando el dataset original
datos_filtrados <- datos %>%
# Me quedo con los que pertenecen a Argentina y Capital Federal
filter(l1 == "Argentina",
l2 == "Capital Federal",
# cuyo precio este en dolares
currency == "USD",
# propiedad tipo Departamento, PH o Casa
property_type %in% c("Departamento", "PH", "Casa"),
# operaciones de venta
operation_type == "Venta")
# chequeo si el filtro se refleja correctamente en mi nuevo dataset datos1b
head(datos_filtrados)
# veo la dimension del nuevo dataset
dim(datos_filtrados) # 61905  24
#selecciono solo las variables de la consigna (9 de las 24)
datos_selec <- datos_filtrados %>%
select(id, l3, rooms, bedrooms, bathrooms, surface_total, surface_covered, price, property_type)
# chequeo que la seleccion sea correcta
head(datos_selec)
# chequeo la dimension
glimpse(datos_selec)
# Armo una tabla por variable que indique cantidad de faltantes y valores unicos que existe en el dataset
tabla <- datos_selec %>% gather(.,
key   = Variables,
value = Valores) %>%
group_by(Variables) %>%
summarise(valores_unicos = n_distinct(Valores),
valores_faltantes = sum(is.na(Valores)),
porcentaje_faltantes = round(sum(is.na(Valores))/nrow(datos_selec)*100,2)) %>%
arrange(desc(porcentaje_faltantes), valores_unicos) # ordenamos por porcentaje de faltantes y valores unicos
tabla
tabla %>%
filter(porcentaje_faltantes>0) %>%
ggplot(., aes(x=reorder(Variables, -porcentaje_faltantes), y=porcentaje_faltantes, fill=porcentaje_faltantes)) +
geom_bar(stat = "identity") +
scale_fill_gradient(high = "firebrick", low = "orange") +
scale_x_discrete(label = function(x) stringr::str_trunc(x, 18)) +
theme_bw() +
theme(axis.text.x = element_text(angle=80, vjust=0.5), legend.position = "none") +
labs(title='Porcentaje de valores faltantes', y='Porcentaje de faltantes', x='')
# calculo matriz de correlacion para los registros completos (omitiendo faltantes) con ambos métodos
# pearson
# selecciono variables numericas para poder calcular la matriz de correlacion
matriz.correl.pe <- datos_selec %>% select(where(is.numeric)) %>%
correlate(use = "complete.obs", method = "pearson") %>%
shave() %>%
fashion()
# spearman
matriz.correl.sp <- datos_selec %>% select(where(is.numeric)) %>%
correlate(use = "complete.obs", method = "spearman")
# armo tabla de correlación con este último método
matriz.correl.sp %>%
shave() %>%
fashion()
# armo nuevo dataset excluyendo la variable bedroom
datos_limpios <- datos_selec %>%
select(-c(bedrooms))
# chequeo que la haya eliminado
head(datos_limpios)
# elimino los registros faltantes
datos_limpios <- datos_limpios %>% drop_na()
# chequeo no haya registros faltantes
head(datos_limpios)
# chequeo dimension de mi nuevo dataset
dim(datos_limpios) #51210  8
# elimino los registros erróneos
datos_limpios <- datos_limpios %>%
filter(surface_total>=surface_covered)
# chequeo dimension de mi nuevo dataset
dim(datos_limpios) # 50828  8
# genero una nueva variable de precios en miles para reducir escala en el gráfico
datos_limpios <- datos_limpios %>%
mutate(precio_en_miles = round((price/1e3),0))
# Calculo estadisticas descriptivas de la variable precio
# minimo, primer cuartil (Q1), mediana (o Q2), promedio, Q3 y maximo
estad.descrip.precios <- datos_limpios %>%
summarise(Minimo = min(precio_en_miles),
Q1 = quantile(precio_en_miles, probs = 0.25),
Mediana = quantile(precio_en_miles, probs = 0.5),
Promedio = round(mean(precio_en_miles),0),
Q3 = quantile(precio_en_miles, probs = 0.75),
Maximo = max(precio_en_miles),
Desvio = round(sd(precio_en_miles),0))
# tabla resultante
estad.descrip.precios
# Armo histograma de precios de las propiedades
ggplot(data = datos_limpios, aes(x = precio_en_miles)) +
geom_histogram(col = "white", aes( fill = ..count..), alpha = 0.75) +
labs(title = "Histograma de precios de propiedades") +
labs(x = "Precio en miles de USD") +
theme_bw()
# calculo estadisticas descriptivas pero agrupando por tipo de propiedad
datos_limpios %>%
group_by(property_type) %>%
summarise(Freq_abs = length(precio_en_miles),
Freq_rel = round(length(precio_en_miles)/nrow(datos_limpios)*100,2) ,
Minimo = min(precio_en_miles), Q1 = quantile(precio_en_miles, probs = 0.25),
Mediana = quantile(precio_en_miles, probs = 0.5),
Promedio = round(mean(precio_en_miles),0),
Q3 = quantile(precio_en_miles, probs = 0.75),
Maximo = max(precio_en_miles),
Desvio = round(sd(precio_en_miles),0))
# armo boxplots paralelos segun el tipo de propiedad (casa, dpto o ph)
ggplot(datos_limpios, aes(y = precio_en_miles, group = property_type, fill = property_type )) +
geom_boxplot() +
labs(title = "Boxplots de precios por tipo de propiedad")+
theme(legend.position = 'none') +
scale_fill_brewer(palette = "PRGn") +
labs(y = "Precio en miles de USD") +
labs(x = "Tipo de propiedad") +
facet_wrap(~ property_type) +
theme_bw()
# Acotando la escala del grafico para visualizar mejor el 50% centra de datos
ggplot(datos_limpios, aes(y = precio_en_miles, group = property_type, fill = property_type )) +
geom_boxplot() +
labs(title = "Boxplots de precios por tipo de propiedad (escala acotada)")+
scale_fill_brewer(palette = "PRGn") +
theme(legend.position = 'none') +
scale_y_continuous(limits = c(0, 1000)) +
labs(y = "Precio en miles de USD") +
labs(x = "Tipo de propiedad") +
facet_wrap(~ property_type) +
theme_bw()
library(GGally)
# graficamos con ggpairs coloreando por property type
# descartando variables no numéricas y el precio para no duplicar la información que ya tenemos en precio_en_miles
ggpairs(datos_limpios %>% select(-c("id", "l3", "price")),
aes(color = property_type),
progress = FALSE,
upper = list(continuous = wrap("cor", size = 3, hjust=0.7)),
legend = 25) +
theme_bw() +
theme(axis.text.x = element_text(angle=45, vjust=0.5), legend.position = "bottom")
# grafico los precios en funcion superficie para detectar algun outlier visualmente
ggplot(datos_limpios, aes(x = surface_total, y = precio_en_miles, color = property_type)) +
geom_point(alpha = 0.75) +
scale_color_brewer(palette = "Set1") +
theme(legend.position = "none") +
theme_minimal() +
labs(y = "Precios en miles", x = "Superficie total") +
ggtitle("Scatterplot: precios en función de superficie total")
# se grafica adicionalmente la variable rooms para detectar presencia de valores atípicos
ggplot(datos_limpios, aes(x = rooms, y = precio_en_miles, color = property_type)) +
geom_point(alpha = 0.75) +
scale_color_brewer(palette = "Set1") +
theme(legend.position = "none") +
theme_minimal() +
labs(y = "Precios por metro cuadrado", x = "Número de habitaciones") +
ggtitle("Scatterplot: precios en función del número de habitaciones")
# chequeo algunos registros que parecen atípicos
max(datos_limpios$surface_total)
max(datos_limpios$rooms)
# armo una nueva variable que sea precios por metro (superficie)
datos_sin_outliers <- datos_limpios %>%
mutate(pxmt = round(price/surface_total,0))
summary(datos_sin_outliers$pxmt)
# Armo histograma de precios x metro cuadrado
ggplot(data = datos_sin_outliers, aes(x = pxmt)) +
geom_histogram(col = "white", aes( fill = ..count..), alpha = 0.75) +
labs(title = "Histograma de precios por m2 de propiedades") +
labs(x = "Precio por m2") +
theme_bw()
pxmt_sup = IQR(datos_sin_outliers$pxmt) * 3 + quantile(datos_sin_outliers$pxmt, 0.75)
pxmt_sup
pxmt_inf = quantile(datos_sin_outliers$pxmt, 0.25) - IQR(datos_sin_outliers$pxmt) * 3
pxmt_inf
rooms_sup = IQR(datos_sin_outliers$rooms) * 3 + quantile(datos_sin_outliers$rooms, 0.75)
rooms_sup
rooms_inf = quantile(datos_sin_outliers$rooms, 0.25) - IQR(datos_sin_outliers$rooms) * 3
rooms_inf
datos_sin_outliers = datos_sin_outliers %>%
filter(between(pxmt, 750, pxmt_sup), between(rooms, 0, rooms_sup)) # redondeo en 500 el 496.5 y pongo el valor minimo de una casa no puede ser menor a 10 mil
glimpse(datos_sin_outliers)# 49835
nrow(datos_limpios) - nrow(datos_sin_outliers)
# Tabla de estadisticas descriptivas de la variable precio para el nuevo conjunto de datos sin outliers
datos_sin_outliers %>%
summarise(Minimo = min(precio_en_miles),
Q1 = quantile(precio_en_miles, probs = 0.25),
Mediana = quantile(precio_en_miles, probs = 0.5),
Promedio = round(mean(precio_en_miles),0),
Q3 = quantile(precio_en_miles, probs = 0.75),
Maximo = max(precio_en_miles),
Desvio = round(sd(precio_en_miles),0))
# Armo histograma para ver distribucion de precios en miles del nuevo dataset
ggplot(data = datos_sin_outliers, aes(x = precio_en_miles)) +
geom_histogram(col = "white", aes( fill = ..count..), alpha = 0.75) +
labs(title = "Histograma de precios de propiedades") +
labs(x = "Precio en miles de USD") +
theme_minimal()
# Tabla de estadisticas descriptivas por tipo de propiedad
datos_sin_outliers %>%
group_by(property_type) %>%
summarise(Minimo = min(precio_en_miles), Q1 = quantile(precio_en_miles, probs = 0.25), Mediana = quantile(precio_en_miles, probs = 0.5), Promedio = round(mean(precio_en_miles),0), Q3 = quantile(precio_en_miles, probs = 0.75),  Maximo = max(precio_en_miles), Desvio = round(sd(precio_en_miles),0))
# Armo boxplots paralelos segun el tipo de propiedad (casa, dpto o ph) con el nuevo dataset
ggplot(datos_sin_outliers, aes(y = precio_en_miles, fill = property_type )) +
geom_boxplot() +
labs(title = "Boxplots de precios por tipo de propiedad")+
theme(legend.position = 'none') +
theme_minimal() +
scale_fill_brewer(palette = "PRGn") +
scale_y_continuous() +
labs(y = "Precio en miles de USD") +
labs(x = "Tipo de propiedad") +
facet_wrap(~ property_type)
# Armo boxplots paralelos de precios por metro cuadrado segun el tipo de propiedad sin outliers
ggplot(datos_sin_outliers, aes(y = precio_en_miles, fill = property_type )) +
geom_boxplot() +
labs(title = "Boxplots de precios por tipo de propiedad") +
theme(legend.position = 'none') +
theme_minimal() +
scale_fill_brewer(palette = "PRGn") +
scale_y_continuous() +
labs(y = "Precio en miles") +
labs(x = "Tipo de propiedad") +
facet_wrap(~ property_type)
# armo scatterplot de precios en miles en función de superficie total
ggplot(datos_sin_outliers, aes(x = surface_total, y = precio_en_miles, color = property_type)) +
geom_point(alpha = 0.75) +
scale_color_brewer(palette = "Set1") +
theme(legend.position = "none") +
theme_minimal() +
labs(y = "Precios en miles", x = "Superficie total") +
ggtitle("Scatterplot: precios en función de superficie total")
# Armo histograma de precios x metro cuadrado
ggplot(data = datos_sin_outliers, aes(x = pxmt)) +
geom_histogram(col = "white", aes( fill = ..count..), alpha = 0.75) +
labs(title = "Histograma de precios por m2 de propiedades") +
labs(x = "Precio por m2") +
theme_minimal()
datos_sin_outliers %>%
# descartando variables no numéricas y el precio para no duplicar la información que ya tenemos en precio_en_miles
select(-c("id", "l3", "price", "pxmt")) %>%
ggpairs(., aes(color = property_type), upper = list(continuous = wrap("cor", size = 3, hjust=0.7)), legend = 25, progress = FALSE) +
theme_bw() +
theme(axis.text.x = element_text(angle=45, vjust=0.5), legend.position = "bottom")
glimpse(datos_sin_outliers)
write.csv(datos_sin_outliers %>% select(-c(pxmt)), file = "properati_preprocesado.csv", row.names=FALSE)
write_csv(datos_sin_outliers %>% select(-c(pxmt)), file = "properati_preprocesado_.csv")
# Lectura
data <- load_dataset(file = "../datasets/properati_preprocesado.csv", encoding='UTF-8'))
# Lectura
data <- load_dataset(file = "../datasets/properati_preprocesado.csv", encoding='UTF-8')
# Lectura
data <- load_dataset(file = "../datasets/properati_preprocesado_.csv", encoding='UTF-8')
# Lectura
data <- load_dataset(file = "../datasets/properati_preprocesado_.csv", encoding='UTF-8')
